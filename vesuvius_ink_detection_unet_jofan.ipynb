{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNG4goF9+Wtgp5OCMaIQs+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JFchien/DataVisualization/blob/main/vesuvius_ink_detection_unet_jofan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ktvLvXmDXk7",
        "outputId": "a30274a0-ba68-4f66-def6-1cf57afd3ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "PREFIX = '/content/gdrive/MyDrive/train/1/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # check if data is loaded\n",
        "# mask = np.array(Image.open(PREFIX+\"mask.png\").convert('1'))\n",
        "# label = torch.from_numpy(np.array(Image.open(PREFIX+\"inklabels.png\"))).gt(0).float().to(DEVICE)\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "# ax1.set_title(\"mask.png\")\n",
        "# ax1.imshow(mask, cmap='gray')\n",
        "# ax2.set_title(\"inklabels.png\")\n",
        "# ax2.imshow(label.cpu(), cmap='gray')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "SiMJBIX0Dmfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vesuvius 3D UNET"
      ],
      "metadata": {
        "id": "G1_or6rMLUZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "PREFIX = '/content/gdrive/MyDrive/train/1/'\n",
        "\n",
        "class SubvolumeDataset(data.Dataset):\n",
        "    def __init__(self, image_stack, label, pixels):\n",
        "        self.image_stack = image_stack\n",
        "        self.label = label\n",
        "        self.pixels = pixels\n",
        "    def __len__(self):\n",
        "        return len(self.pixels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y, x = self.pixels[index]\n",
        "        subvolume = self.image_stack[:, y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1, Z_DIM,BUFFER*2, BUFFER*2)\n",
        "        inklabel = self.label[y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1,BUFFER*2, BUFFER*2)\n",
        "        return subvolume, inklabel\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "          nn.Conv3d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.Conv3d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "        self.maxpool=nn.MaxPool3d(kernel_size=2)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        x = self.down_conv(inputs)\n",
        "        p = self.maxpool(x)\n",
        "        return x, p\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_c, out_c, kernel_size=2,  stride=2, padding=0)\n",
        "        self.up_conv = nn.Sequential(\n",
        "          nn.Conv3d(in_c, out_c, kernel_size=3, stride=1,padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv3d(out_c, out_c, kernel_size=3,stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, crop):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, crop], dim=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Down(1, 64)\n",
        "        self.d2 = Down(64, 128)\n",
        "        self.d3 = Down(128, 256)\n",
        "        self.d4 = Down(256, 512)\n",
        "        self.bottleneck = Down(512, 1024)\n",
        "        self.u4 = Up(1024, 512)\n",
        "        self.u3 = Up(512, 256)\n",
        "        self.u2 = Up(256, 128)\n",
        "        self.u1 = Up(128, 64)\n",
        "        self.outputs = nn.Conv3d(64, 1, kernel_size=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        x1, p1 = self.d1(x)\n",
        "#         print(f\"Size of x1: {x1.size()}\")\n",
        "#         print(f\"Size of p1: {p1.size()}\")\n",
        "        x2, p2 = self.d2(p1)\n",
        "#         print(f\"Size of x2: {x2.size()}\")\n",
        "#         print(f\"Size of p2: {p2.size()}\")\n",
        "        x3, p3 = self.d3(p2)\n",
        "#         print(f\"Size of x3: {x3.size()}\")\n",
        "#         print(f\"Size of p3: {p3.size()}\")\n",
        "        x4, p4 = self.d4(p3)\n",
        "#         print(f\"Size of x4: {x4.size()}\")\n",
        "#         print(f\"Size of p4: {p4.size()}\")\n",
        "        b, _ = self.bottleneck(p4)\n",
        "#         print(f\"Size of b: {b.size()}\")\n",
        "        u4 = self.u4(b,x4)\n",
        "#         print(f\"Size of u4: {u4.size()}\")\n",
        "        u3 = self.u3(u4,x3)\n",
        "        u2 = self.u2(u3,x2)\n",
        "        u1 = self.u1(u2,x1)\n",
        "        outputs = self.outputs(u1)\n",
        "        return outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUNKHPvrLTQT",
        "outputId": "2d95457d-7915-4b78-85d1-59fcf4901eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BUFFER=int(512/2)\n",
        "rect = (1100, 3500, BUFFER*3, BUFFER*3)\n",
        "LEARNING_RATE = 0.03\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "mask = np.array(Image.open(PREFIX+\"mask.png\").convert('1'))\n",
        "label = torch.from_numpy(np.array(Image.open(PREFIX+\"inklabels.png\"))).gt(0).float().to(DEVICE)\n",
        "Z_START = 1\n",
        "Z_END = 65\n",
        "Z_DIM=Z_END-Z_START\n",
        "images = [np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tqdm(sorted(glob.glob(PREFIX+\"surface_volume/*.tif\"))[Z_START:Z_END])]\n",
        "image_stack = torch.stack([torch.from_numpy(image) for image in images], dim=0).to(DEVICE)\n",
        "print(image_stack.shape)\n",
        "del images\n",
        "not_border = np.zeros(mask.shape, dtype=bool)\n",
        "not_border[BUFFER:mask.shape[0]-BUFFER, BUFFER:mask.shape[1]-BUFFER] = True\n",
        "arr_mask = np.array(mask) * not_border\n",
        "inside_rect = np.zeros(mask.shape, dtype=bool) * arr_mask\n",
        "inside_rect[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]] = True\n",
        "outside_rect = np.ones(mask.shape, dtype=bool) * arr_mask\n",
        "outside_rect[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]] = False\n",
        "pixels_inside_rect = np.argwhere(inside_rect)\n",
        "pixels_outside_rect = np.argwhere(outside_rect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Ff0xAWL21l",
        "outputId": "7d15c608-975d-484f-e14d-f8ad0d1a251a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:17<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8181, 6330])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "TRAINING_STEPS = 5\n",
        "model = Unet().to(DEVICE)\n",
        "train_dataset = SubvolumeDataset(image_stack, label, pixels_outside_rect)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, total_steps=TRAINING_STEPS)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    train_loss = 0\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (subvolumes, inklabels) in tqdm(enumerate(dataloader), total=TRAINING_STEPS):\n",
        "        if i >= TRAINING_STEPS:\n",
        "            break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(subvolumes.to(DEVICE))\n",
        "        loss = loss_fn(outputs, inklabels.to(DEVICE))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#         scheduler.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(dataloader)\n",
        "    print(f\"Train Error: Avg loss: {train_loss:>8f} \\n\")\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "eval_dataset = SubvolumeDataset(image_stack, label, pixels_inside_rect)\n",
        "eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (subvolumes, inklabels) in tqdm(enumerate(dataloader), total=TRAINING_STEPS):\n",
        "            if i >= TRAINING_STEPS:\n",
        "                break\n",
        "            outputs = model(subvolumes.to(DEVICE))\n",
        "            loss = loss_fn(outputs, inklabels.to(DEVICE))\n",
        "            test_loss += loss.item()\n",
        "    test_loss /= len(dataloader)\n",
        "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return test_loss\n",
        "\n",
        "epochs = 2\n",
        "train_loss_all = []\n",
        "test_loss_all = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    test_loss = test_loop(eval_loader, model, loss_fn)\n",
        "\n",
        "    train_loss_all.append(train_loss)\n",
        "    test_loss_all.append(test_loss)\n",
        "\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uMIIwtiMTt5",
        "outputId": "075a0a70-c312-480a-9137-7765746e447f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vesuvius 2D UNET"
      ],
      "metadata": {
        "id": "2wCXgfipLLwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "PREFIX = '/content/gdrive/MyDrive/train/1/'\n",
        "\n",
        "class SubvolumeDataset2D(data.Dataset):\n",
        "    def __init__(self, image_stack, label, pixels):\n",
        "        self.image_stack = image_stack\n",
        "        self.label = label\n",
        "        self.pixels = pixels\n",
        "    def __len__(self):\n",
        "        return len(self.pixels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y, x = self.pixels[index]\n",
        "        subvolume = self.image_stack[y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1,BUFFER*2, BUFFER*2)\n",
        "        inklabel = self.label[y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1,BUFFER*2, BUFFER*2)\n",
        "        return subvolume, inklabel\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "          nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        x = self.down_conv(inputs)\n",
        "        p = self.maxpool(x)\n",
        "        return x, p\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2,  stride=2, padding=0)\n",
        "        self.up_conv = nn.Sequential(\n",
        "          nn.Conv2d(in_c, out_c, kernel_size=3, stride=1,padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(out_c, out_c, kernel_size=3,stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, crop):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, crop], axis=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Down(1, 64)\n",
        "        self.d2 = Down(64, 128)\n",
        "        self.d3 = Down(128, 256)\n",
        "        self.d4 = Down(256, 512)\n",
        "        self.bottleneck = Down(512, 1024)\n",
        "        self.u4 = Up(1024, 512)\n",
        "        self.u3 = Up(512, 256)\n",
        "        self.u2 = Up(256, 128)\n",
        "        self.u1 = Up(128, 64)\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        x1, p1 = self.d1(x)\n",
        "#         print(f\"Size of x1: {x1.size()}\")\n",
        "#         print(f\"Size of p1: {p1.size()}\")\n",
        "        x2, p2 = self.d2(p1)\n",
        "#         print(f\"Size of x2: {x2.size()}\")\n",
        "#         print(f\"Size of p2: {p2.size()}\")\n",
        "        x3, p3 = self.d3(p2)\n",
        "#         print(f\"Size of x3: {x3.size()}\")\n",
        "#         print(f\"Size of p3: {p3.size()}\")\n",
        "        x4, p4 = self.d4(p3)\n",
        "#         print(f\"Size of x4: {x4.size()}\")\n",
        "#         print(f\"Size of p4: {p4.size()}\")\n",
        "        b, _ = self.bottleneck(p4)\n",
        "#         print(f\"Size of b: {b.size()}\")\n",
        "        u4 = self.u4(b,x4)\n",
        "#         print(f\"Size of u4: {u4.size()}\")\n",
        "        u3 = self.u3(u4,x3)\n",
        "        u2 = self.u2(u3,x2)\n",
        "        u1 = self.u1(u2,x1)\n",
        "        outputs = self.outputs(u1)\n",
        "        return outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZCH2_G2DzAG",
        "outputId": "edde2499-de0e-47d8-ef24-5e8b5065011f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BUFFER=int(512/2)\n",
        "rect = (1100, 3500, BUFFER*3, BUFFER*3)\n",
        "LEARNING_RATE = 0.03\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "mask = np.array(Image.open(PREFIX+\"mask.png\").convert('1'))\n",
        "label = torch.from_numpy(np.array(Image.open(PREFIX+\"inklabels.png\"))).gt(0).float().to(DEVICE)\n",
        "Z_START = 10\n",
        "Z_END = 50\n",
        "images = [np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tqdm(sorted(glob.glob(PREFIX+\"surface_volume/*.tif\"))[Z_START:Z_END])]\n",
        "image_stack_flatten = torch.mean(torch.stack([torch.from_numpy(image) for image in images], dim=0), dim=0).to(DEVICE)\n",
        "print(image_stack_flatten.shape)\n",
        "del images\n",
        "not_border = np.zeros(mask.shape, dtype=bool)\n",
        "not_border[BUFFER:mask.shape[0]-BUFFER, BUFFER:mask.shape[1]-BUFFER] = True\n",
        "arr_mask = np.array(mask) * not_border\n",
        "inside_rect = np.zeros(mask.shape, dtype=bool) * arr_mask\n",
        "inside_rect[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]] = True\n",
        "outside_rect = np.ones(mask.shape, dtype=bool) * arr_mask\n",
        "outside_rect[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]] = False\n",
        "pixels_inside_rect = np.argwhere(inside_rect)\n",
        "pixels_outside_rect = np.argwhere(outside_rect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9TNX7JFDzy4",
        "outputId": "fd8e8199-dda2-439f-84a3-9a3b0ce26e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:20<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8181, 6330])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "TRAINING_STEPS = 3000\n",
        "model = Unet().to(DEVICE)\n",
        "train_dataset = SubvolumeDataset2D(image_stack_flatten, label, pixels_outside_rect)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, total_steps=TRAINING_STEPS)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    train_loss = 0\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (subvolumes, inklabels) in tqdm(enumerate(dataloader), total=TRAINING_STEPS):\n",
        "        if i >= TRAINING_STEPS:\n",
        "            break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(subvolumes.to(DEVICE))\n",
        "        loss = loss_fn(outputs, inklabels.to(DEVICE))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#         scheduler.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(dataloader)\n",
        "    print(f\"Train Error: Avg loss: {train_loss:>8f} \\n\")\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "eval_dataset = SubvolumeDataset2D(image_stack_flatten, label, pixels_inside_rect)\n",
        "eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (subvolumes, inklabels) in tqdm(enumerate(dataloader), total=TRAINING_STEPS):\n",
        "            if i >= TRAINING_STEPS:\n",
        "                break\n",
        "            outputs = model(subvolumes.to(DEVICE))\n",
        "            loss = loss_fn(outputs, inklabels.to(DEVICE))\n",
        "            test_loss += loss.item()\n",
        "    test_loss /= len(dataloader)\n",
        "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return test_loss\n",
        "\n",
        "epochs = 30\n",
        "train_loss_all = []\n",
        "test_loss_all = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    test_loss = test_loop(eval_loader, model, loss_fn)\n",
        "\n",
        "    train_loss_all.append(train_loss)\n",
        "    test_loss_all.append(test_loss)\n",
        "\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ybgp11BWEfwM",
        "outputId": "2d655890-db93-46b7-a05a-99a9d683906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [05:30<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: Avg loss: 0.000063 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:42<00:00, 29.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: Avg loss: 0.002647 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [05:28<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: Avg loss: 0.000057 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:42<00:00, 29.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: Avg loss: 0.002502 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [05:28<00:00,  9.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: Avg loss: 0.000028 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:42<00:00, 29.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: Avg loss: 0.001641 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [05:28<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: Avg loss: 0.000011 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:42<00:00, 29.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: Avg loss: 0.000629 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [05:28<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: Avg loss: 0.000007 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:42<00:00, 29.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: Avg loss: 0.000518 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 722/3000 [01:20<04:14,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-55ef169e819b>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-55ef169e819b>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_all)\n",
        "plt.plot(test_loss_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "yISSwLgUHcd6",
        "outputId": "9dfbc3dd-4310-4a6c-9ef2-a36fc0b3b0ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7dcd48381cf0>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test 2D UNET"
      ],
      "metadata": {
        "id": "gstr12raHmxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "class SubvolumeDataset2D(data.Dataset):\n",
        "    def __init__(self, image_stack, label, pixels):\n",
        "        self.image_stack = image_stack\n",
        "        self.label = label\n",
        "        self.pixels = pixels\n",
        "    def __len__(self):\n",
        "        return len(self.pixels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        y, x = self.pixels[index]\n",
        "        subvolume = self.image_stack[y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1,BUFFER*2, BUFFER*2)\n",
        "        inklabel = self.label[y-BUFFER:y+BUFFER, x-BUFFER:x+BUFFER].view(1,BUFFER*2, BUFFER*2)\n",
        "        return subvolume, inklabel\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "          nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        x = self.down_conv(inputs)\n",
        "        p = self.maxpool(x)\n",
        "        return x, p\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2,  stride=2, padding=0)\n",
        "        self.up_conv = nn.Sequential(\n",
        "          nn.Conv2d(in_c, out_c, kernel_size=3, stride=1,padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(out_c, out_c, kernel_size=3,stride=1, padding=1),\n",
        "          nn.BatchNorm2d(out_c),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, crop):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, crop], axis=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Down(1, 64)\n",
        "        self.d2 = Down(64, 128)\n",
        "        self.d3 = Down(128, 256)\n",
        "        self.d4 = Down(256, 512)\n",
        "        self.bottleneck = Down(512, 1024)\n",
        "        self.u4 = Up(1024, 512)\n",
        "        self.u3 = Up(512, 256)\n",
        "        self.u2 = Up(256, 128)\n",
        "        self.u1 = Up(128, 64)\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        x1, p1 = self.d1(x)\n",
        "#         print(f\"Size of x1: {x1.size()}\")\n",
        "#         print(f\"Size of p1: {p1.size()}\")\n",
        "        x2, p2 = self.d2(p1)\n",
        "#         print(f\"Size of x2: {x2.size()}\")\n",
        "#         print(f\"Size of p2: {p2.size()}\")\n",
        "        x3, p3 = self.d3(p2)\n",
        "#         print(f\"Size of x3: {x3.size()}\")\n",
        "#         print(f\"Size of p3: {p3.size()}\")\n",
        "        x4, p4 = self.d4(p3)\n",
        "#         print(f\"Size of x4: {x4.size()}\")\n",
        "#         print(f\"Size of p4: {p4.size()}\")\n",
        "        b, _ = self.bottleneck(p4)\n",
        "#         print(f\"Size of b: {b.size()}\")\n",
        "        u4 = self.u4(b,x4)\n",
        "#         print(f\"Size of u4: {u4.size()}\")\n",
        "        u3 = self.u3(u4,x3)\n",
        "        u2 = self.u2(u3,x2)\n",
        "        u1 = self.u1(u2,x1)\n",
        "        outputs = self.outputs(u1)\n",
        "        return outputs\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Unet().to(DEVICE)\n",
        "img=torch.rand(1,1,512,512)\n",
        "out=model(img.to(DEVICE))\n",
        "print(img.shape)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "A3GiamB3Hp2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu_LFVWlHs5m",
        "outputId": "08d43c53-7e89-474a-857f-f742e9e92efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 512, 512])\n",
            "torch.Size([1, 1, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test 3D UNET"
      ],
      "metadata": {
        "id": "TDxDb8RrHhiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "          nn.Conv3d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.Conv3d(out_c, out_c, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "        self.maxpool=nn.MaxPool3d(kernel_size=2)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        x = self.down_conv(inputs)\n",
        "        p = self.maxpool(x)\n",
        "        return x, p\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_c, out_c, kernel_size=2,  stride=2, padding=0)\n",
        "        self.up_conv = nn.Sequential(\n",
        "          nn.Conv3d(in_c, out_c, kernel_size=3, stride=1,padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv3d(out_c, out_c, kernel_size=3,stride=1, padding=1),\n",
        "          nn.BatchNorm3d(out_c),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, crop):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, crop], dim=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Down(1, 64)\n",
        "        self.d2 = Down(64, 128)\n",
        "        self.d3 = Down(128, 256)\n",
        "        self.d4 = Down(256, 512)\n",
        "        self.bottleneck = Down(512, 1024)\n",
        "        self.u4 = Up(1024, 512)\n",
        "        self.u3 = Up(512, 256)\n",
        "        self.u2 = Up(256, 128)\n",
        "        self.u1 = Up(128, 64)\n",
        "        self.outputs = nn.Conv3d(64, 1, kernel_size=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        x1, p1 = self.d1(x)\n",
        "#         print(f\"Size of x1: {x1.size()}\")\n",
        "#         print(f\"Size of p1: {p1.size()}\")\n",
        "        x2, p2 = self.d2(p1)\n",
        "#         print(f\"Size of x2: {x2.size()}\")\n",
        "#         print(f\"Size of p2: {p2.size()}\")\n",
        "        x3, p3 = self.d3(p2)\n",
        "#         print(f\"Size of x3: {x3.size()}\")\n",
        "#         print(f\"Size of p3: {p3.size()}\")\n",
        "        x4, p4 = self.d4(p3)\n",
        "#         print(f\"Size of x4: {x4.size()}\")\n",
        "#         print(f\"Size of p4: {p4.size()}\")\n",
        "        b, _ = self.bottleneck(p4)\n",
        "#         print(f\"Size of b: {b.size()}\")\n",
        "        u4 = self.u4(b,x4)\n",
        "#         print(f\"Size of u4: {u4.size()}\")\n",
        "        u3 = self.u3(u4,x3)\n",
        "        u2 = self.u2(u3,x2)\n",
        "        u1 = self.u1(u2,x1)\n",
        "        outputs = self.outputs(u1)\n",
        "        return outputs\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "model = Unet().to(DEVICE)\n",
        "img=torch.rand(1,1,64,512,512)\n",
        "out=model(img.to(DEVICE))\n",
        "print(img.shape)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9CtM1svHchX",
        "outputId": "5263f809-ca42-404c-a7d7-961576dc1e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 64, 512, 512])\n",
            "torch.Size([1, 1, 64, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnreK-3FHetv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}